{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Py4Eng](img/logo.png)\n",
    "\n",
    "# Recurrent Neural Networks\n",
    "## Yoav Ram\n",
    "\n",
    "In this session we will understand:\n",
    "- what recurrent neural network and how they work, and\n",
    "- how memory and state can be implemented in neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from random import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In developing this RNN we will follow [Andrej Karpathy](http://cs.stanford.edu/people/karpathy/)'s [blogpost about RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness) ([original code gist](https://gist.github.com/karpathy/d4dee566867f8291f086) with BSD License).\n",
    "\n",
    "The data is just text data, in this case Shakespear's writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 99993\n",
      "Number of unique characters: 62\n",
      "Number of lines: 3298\n",
      "Number of words: 15893\n",
      "\n",
      "Excerpt:\n",
      "********\n",
      "That, poor contempt, or claim'd thou slept so faithful,\n",
      "I may contrive our father; and, in their defeated queen,\n",
      "Her flesh broke me and puttance of expedition house,\n",
      "And in that same that ever I lament this stomach,\n",
      "And he, nor Butly and my fury, knowing everything\n",
      "Grew daily ever, his great strength and thought\n",
      "The bright buds of mine own.\n",
      "\n",
      "BIONDELLO:\n",
      "Marry, that it may not pray their patience.'\n",
      "\n",
      "KING LEAR:\n",
      "The instant common maid, as we may less be\n",
      "a brave gentleman and joiner: he that finds u\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/shakespear.txt'\n",
    "text = open(filename, 'rt').read()\n",
    "print(\"Number of characters: {}\".format(len(text)))\n",
    "print(\"Number of unique characters: {}\".format(len(set(text))))\n",
    "print(\"Number of lines: {}\".format(text.count('\\n')))\n",
    "print(\"Number of words: {}\".format(text.count(' ')))\n",
    "print()\n",
    "print(\"Excerpt:\")\n",
    "print(\"*\" * len(\"Excerpt:\"))\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations\n",
    "\n",
    "We start by creating \n",
    "- a list `chars` of the unique characters\n",
    "- `data_size` the number of total characters\n",
    "- `vocab_size` the number of unique characters\n",
    "- `idx_to_char` a dictionary from index to char\n",
    "- `char_to_idx` a dictionary from char to index\n",
    "and then we convert `data` from a string to a NumPy array integers representing the chars via their indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(set(text))\n",
    "data_size, vocab_size = len(text), len(chars)\n",
    "\n",
    "idx_to_char = dict(enumerate(chars)) # { i: ch for i,ch in enumerate(chars) }\n",
    "char_to_idx = dict(zip(idx_to_char.values(), idx_to_char.keys())) # { ch: i for i,ch in enumerate(chars) }\n",
    "data = np.array([char_to_idx[c] for c in text], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some of the functions we already know out of the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x.squeeze()\n",
    "    expx = np.exp(x - x.sum())\n",
    "    return expx / expx.sum()\n",
    "\n",
    "def cross_entropy(predictions, targets):\n",
    "    return sum([-np.log(p[t]) for p, t in zip(predictions, targets)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(prev, curr, β):\n",
    "    return [\n",
    "        β * p + (1 - β) * c\n",
    "        for p, c\n",
    "        in zip(prev, curr)\n",
    "    ]\n",
    "    \n",
    "class AdamOptimizer:\n",
    "    def __init__(self, α=0.001, β1=0.9, β2=0.999, ϵ=1e-8):\n",
    "        self.α = α\n",
    "        self.β1 = β1\n",
    "        self.β2 = β2\n",
    "        self.ϵ = ϵ\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.t = 0\n",
    "\n",
    "    def send(self, gradients):\n",
    "        if self.m is None:\n",
    "            self.m = [0] * len(gradients)\n",
    "        if self.v is None:\n",
    "            self.v = [0] * len(gradients)\n",
    "\n",
    "        self.t += 1\n",
    "        αt = self.α * np.sqrt(1 - self.β2**self.t) / (1 - self.β1**self.t)\n",
    "        self.m = average(self.m, gradients, self.β1)        \n",
    "        self.v = average(self.v, (g*g for g in gradients), self.β2)\n",
    "\n",
    "        updates = [-αt * mi / (np.sqrt(vi) + self.ϵ) for mi, vi in zip(self.m, self.v)]\n",
    "        for upd in updates:\n",
    "            assert np.isfinite(upd).all()\n",
    "        return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model\n",
    "\n",
    "- $x(t)$ is the $t$ character, one-hot encoded and a 1D array of length `vocab_size`.\n",
    "- $h(t)$ is the state of the hidden memory layer after seeing $t$ characters, encoded as a 1D array of numbers (neurons...)\n",
    "- $\\widehat y(t)$ is the prediction of the network after seeing $t$ characters, encoded as a 1D array of probabilities of length `vocab_size`\n",
    "\n",
    "The model is then written as:\n",
    "\n",
    "$$\n",
    "h(t) = \\tanh{\\big(x(t) \\cdot W_x^h + h(t-1) \\cdot W_h^h + b_h\\big)} \\\\\n",
    "\\widehat y(t) = softmax\\big(h(t) \\cdot W_h^y\\big)\n",
    "$$\n",
    "\n",
    "and we set $h(0) = (0, \\ldots, 0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation will be performed by our `step` function.\n",
    "\n",
    "The `feed_forward` function will loop over a sequence of $x=(x_1, x_2, \\ldots, x_k)$ of some arbitray size - similar to batches in the FFN and CNN frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(params, x_t, h_t_1=None):\n",
    "    Wxh, Whh, Why, bh, by = params\n",
    "    if h_t_1 is None:\n",
    "        h_t_1 = np.zeros(h_size)    \n",
    "    if h_t_1.ndim == 1:\n",
    "        h_t_1 = h_t_1.reshape(-1, 1)\n",
    "    if x_t.ndim == 1:\n",
    "        x_t = x_t.reshape(-1, 1)\n",
    "\n",
    "    # update hidden layer\n",
    "    h_t = np.tanh(Wxh @ x_t + Whh @ h_t_1 + bh)\n",
    "    # fully connected layer\n",
    "    z_t = Why @ h_t + by\n",
    "    z_t = z_t.squeeze()\n",
    "    h_t = h_t.squeeze()\n",
    "    # softmax readout layer\n",
    "    yhat_t = softmax(z_t)\n",
    "    return h_t, z_t, yhat_t\n",
    "\n",
    "def feed_forward(params, x, h0=None):\n",
    "    if h0 is None:\n",
    "        h0 = np.zeros(h_size)\n",
    "    h = {-1: h0}\n",
    "    \n",
    "    shape = (len(x), vocab_size)\n",
    "    x_original = x.copy()\n",
    "    x, z, yhat = np.zeros(shape), np.empty(shape), np.empty(shape)\n",
    "    \n",
    "    for t, char_idx in enumerate(x_original):\n",
    "        x[t, char_idx] = 1.0 # one-hot encoding input into xs  \n",
    "        h[t], z[t, :], yhat[t, :] = step(params, x[t, :], h[t-1])\n",
    "\n",
    "    return x, h, z, yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back propagation and \"unrolling\" the network\n",
    "\n",
    "Back propagation works, as before, using the chain rule. \n",
    "It is similar to the [FFN example](FFN.ipynb), except that the $h$ layer adds a bit of complexity, but not much.\n",
    "\n",
    "The details of the gradient calculation can be found in Stanford's [\"Convolutional Neural Networks for Visual Recognition\" course](http://cs231n.github.io/neural-networks-case-study/#grad).\n",
    "\n",
    "What's important to discuss is that instead of back propagating a single step of the network $t$, we back propagate over a sequence of steps, that is over $x=(x_1, \\ldots, x_k)$ for some arbitrary $k$.\n",
    "\n",
    "![rolled RNN](img/rolled_rnn.png)\n",
    "\n",
    "How? By \"unrolling\" the network.\n",
    "\n",
    "![Unrolled RNN](img/unrolled_rnn.png)\n",
    "\n",
    "For example, for $k=3$, the input is $x=[x(1), x(2), x(3)]$, and we can write\n",
    "\n",
    "$$\n",
    "h(1) = \\tanh{\\big(x(1) \\cdot W_x^h + h(0) \\cdot W_h^h + b_h\\big)} \\\\\n",
    "\\widehat y(1) = softmax\\big(h(1) \\cdot W_h^y\\big) \\\\\n",
    "h(2) = \\tanh{\\big(x(2) \\cdot W_x^h + h(1) \\cdot W_h^h + b_h\\big)} \\\\\n",
    "\\widehat y(2) = softmax\\big(h(2) \\cdot W_h^y\\big) \\\\\n",
    "h(3) = \\tanh{\\big(x(3) \\cdot W_x^h + h(2) \\cdot W_h^h + b_h\\big)} \\\\\n",
    "\\widehat y(3) = softmax\\big(h(3) \\cdot W_h^y\\big)\n",
    "$$\n",
    "\n",
    "The cross entropy is computed by summing over all $\\widehat y(t)$ together, and then the gradient is computed for this cross entropy with respect to the various $W$ and $b$ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(params, x, y, h0=None):\n",
    "    \"\"\"Calculates loss and gradiens of loss wrt paramters\n",
    "    \n",
    "    See http://cs231n.github.io/neural-networks-case-study/#grad\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : list of arrays\n",
    "        model parameters\n",
    "    x, y : list of integers\n",
    "        indices of characters for the input and target of the network\n",
    "    h : np.ndarray\n",
    "        initial hidden state of shape Hx1\n",
    "    Returns\n",
    "    -------\n",
    "    loss : float\n",
    "        value of loss function\n",
    "    dWxh, dWhh, dWhy, dbh, dby \n",
    "        gradients of the loss function wrt to model parameters\n",
    "    h0 : np.ndarray\n",
    "        initial hidden state\n",
    "    \"\"\"\n",
    "    n_inputs = len(x)\n",
    "    # forward pass: compute predictions and loss going forwards\n",
    "    x, h, z, yhat = feed_forward(params, x, h0=h0)\n",
    "    loss = cross_entropy(yhat, y)\n",
    "    \n",
    "    # backward pass: compute gradients going backwards\n",
    "    Wxh, Whh, Why, bh, by = params\n",
    "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dh_next = np.zeros_like(h[0])\n",
    "    \n",
    "    # back propagate through the unrolled network\n",
    "    for t in reversed(range(len(y))):\n",
    "        # backprop into y\n",
    "        x_t, h_t, yhat_t, y_t = x[t], h[t], yhat[t], y[t] # can't zip because hs is not ordered\n",
    "        dyhat = yhat_t.copy()\n",
    "        dyhat[y_t] -= 1 # Yhat - Y\n",
    "        dWhy += np.outer(dyhat, h_t)  # outer product, same as dy.reshape(-1, 1) @ h.reshape(1, -1)\n",
    "        dby += dyhat.reshape(-1, 1) # dby is a column vector\n",
    "        # backprop into h_t\n",
    "        dh = Why.T @ dyhat + dh_next\n",
    "        # backprop through tanh nonlinearity\n",
    "        dh = (1 - h_t * h_t) * dh # tanh'(x) = 1-x^2\n",
    "        dbh += dh.reshape(-1, 1) # dbh is a column vector\n",
    "        dWxh += np.outer(dh, x_t)\n",
    "        dWhh += np.outer(dh, h[t-1]) # try to use h[t] instead of h[t-1] and see effect in grad_check\n",
    "        dh_next = Whh.T @ dh\n",
    "\n",
    "    gradients = dWxh, dWhh, dWhy, dbh, dby\n",
    "    for grad in gradients:\n",
    "        # clip to mitigate exploding gradients\n",
    "        np.clip(grad, -5, 5, out=grad) # out=grad makes this run in-place\n",
    "    return loss, gradients, h[n_inputs-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer is similar to previous trainers, it goes through the data in `seq_length` batches and then calculates gradients and updates parameters.\n",
    "`seq_length` is not just the batch size for the stochastic gradient descent but also the number of steps to \"unroll\" the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, data, seq_length):\n",
    "        self.optimizer = AdamOptimizer()\n",
    "        self.step, self.pos, self.h = 0, 0, None\n",
    "        self.seq_length = seq_length\n",
    "        self.data = data\n",
    "\n",
    "    def train(self, params):\n",
    "        self.step += 1\n",
    "        if self.pos + self.seq_length + 1 >= len(self.data):\n",
    "            # reset data position and hidden state\n",
    "            self.pos, self.h = 0, None\n",
    "        x = self.data[self.pos : self.pos + self.seq_length]\n",
    "        y = self.data[self.pos + 1 : self.pos + self.seq_length + 1]\n",
    "        \n",
    "        loss, gradients, self.h = back_propagation(params, x, y, self.h)\n",
    "        Δs = self.optimizer.send(gradients)\n",
    "        for par, Δ in zip(params, Δs):\n",
    "            par += Δ\n",
    "        self.pos += self.seq_length\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling from the network\n",
    "\n",
    "Finally, instead of a `predict` function, we have a `sample` function, which, given the parameters $W$s and $b$s), a seed char, number of chars, and an state for the hidden layer, produces a sample of text from the network.\n",
    "\n",
    "It does so by using the seed as $x(1)$ and drawing $x(t)$ for $t>1$ from the distribution given by $\\widehat y(t)$.\n",
    "\n",
    "![](img/sampling_rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(params, seed_idx, num_samples, h0=None):\n",
    "    x = np.zeros((num_samples + 1, vocab_size), dtype=float)\n",
    "    x[0, seed_idx] = 1\n",
    "    idx = np.empty(num_samples, dtype=int)\n",
    "    h_t = h0\n",
    "    for t in range(num_samples):\n",
    "        h_t, _, yhat_t = step(params, x[t, :], h_t)\n",
    "        # draw from output distribution\n",
    "        idx[t] = np.random.choice(range(vocab_size), p=yhat_t.ravel())        \n",
    "        x[t + 1, idx[t]] = 1\n",
    "    chars = (idx_to_char[i] for i in idx)\n",
    "    return str.join('', chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network\n",
    "\n",
    "We can now initialize the parameters and meta-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_size = 100 # number of units in hidden layer\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "max_train_step = 100000\n",
    "\n",
    "Wxh = np.random.randn(h_size, vocab_size) * 0.01 \n",
    "Whh = np.random.randn(h_size, h_size) * 0.01\n",
    "Why = np.random.randn(vocab_size, h_size) * 0.01 \n",
    "bh = np.zeros((h_size, 1)) # hidden layer bias\n",
    "by = np.zeros((vocab_size, 1)) # readout layer bias\n",
    "\n",
    "params = Wxh, Whh, Why, bh, by\n",
    "trainer = Trainer(data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alsnithe een turf\n",
      "Five beed,\n",
      "\n",
      "RAAHY:\n",
      "OnI yee aceye iron me tith-Whe,\n",
      "Tour celloud magiMed rouete titheg I Ar thein bke toind-brom bu hor oun oun mitrhees that hot cnry magn ist es wpasdyn lud heot.\n",
      "AA\n",
      "\n",
      "train step 10000, loss: 52\n",
      "--------------------------------------------------------------------------------\n",
      "an any pncaalt coaid.\n",
      "\n",
      "FFOS:\n",
      "Hatut, palltepd.\n",
      "\n",
      "IAS:\n",
      "Mat an mao dir s om  hake stoyde eull shee nealdaf.\n",
      "\n",
      "TaLld:\n",
      "Rofld whin sith therulnint bise?l, argebshet bedcere: be ant than ghny go nonle thenliin\n",
      "\n",
      "train step 20000, loss: 66\n",
      "--------------------------------------------------------------------------------\n",
      " my a seast urcis shall'd cragh, Hat? at Mendin tcterer ware my youn\n",
      "And ace lall hiidk rey of but;\n",
      "Mare,\n",
      "Themeed to I hellis:\n",
      "WIa in my. do fome breppeis tneart.\n",
      "\n",
      "FAGBENIS:\n",
      "Chite mrine wishe to ceith\n",
      "\n",
      "train step 30000, loss: 59\n",
      "--------------------------------------------------------------------------------\n",
      "e hycAStcet she prake afrenofist be in lmagstojsent heshe angro Cama,\n",
      "Sid a doceth ghith,\n",
      "I mathat whave's Bon waat ane toutes, wers of to geath soroach shecowind-terofs cere, hemelangr pmish youned c\n",
      "\n",
      "train step 40000, loss: 54\n",
      "--------------------------------------------------------------------------------\n",
      "are Sar whis yout mesen moon:\n",
      "Ghe wandom eerseel ard cmat't would nans wlecose\n",
      "Drethe at betour apes aw tik art rounter thabll thec to kin wey dingmere aan cavy and hay I dout foale at I brerit heams \n",
      "\n",
      "train step 50000, loss: 59\n",
      "--------------------------------------------------------------------------------\n",
      "e hra grould doond;\n",
      "Thak dear she you and hoy the nor dist, icefred was ath preemy, thut ivby carcogis to the Ifor of sat to theov as bupedo\n",
      "Sardim gowreat me me's onsush wo whe me hetheld o say bus.\n",
      "\n",
      "\n",
      "train step 60000, loss: 40\n",
      "--------------------------------------------------------------------------------\n",
      "e fo lace\n",
      "Setwoughe hay.\n",
      "And, a som, myre we bead us be, thevere bo trorc.\n",
      "\n",
      "OKI Nszeill whes yourser!\n",
      "\n",
      "DASINGING TERK\n",
      "Whak thy dond the traked yrerid hint mith dous, me of lord sure ho to situer cour \n",
      "\n",
      "train step 70000, loss: 45\n",
      "--------------------------------------------------------------------------------\n",
      "al laraseg of you, with erchabag, and fo inouk, lowd sout the bumnts and\n",
      "And and cathises vavee grom wath's cnalve nut p and, yould rive bucg batbom mas nock\n",
      "To'd and not thou he thef int, ad-Br;stor \n",
      "\n",
      "train step 80000, loss: 60\n",
      "--------------------------------------------------------------------------------\n",
      "teran: ded crathint womet bakpclout to mnich ath a mangarn fowthe brer a oule uedest beed\n",
      "Yous hovestn's me wing cour ath,\n",
      "And han,\n",
      "I'll\n",
      "And sing in is denderent goo not wies a\n",
      "twent and and seak serr\n",
      "\n",
      "train step 90000, loss: 40\n",
      "--------------------------------------------------------------------------------\n",
      "t denothest; I hike pator:\n",
      "\n",
      "SIAEEN:\n",
      "Thou ssfive hall wrere\n",
      "Then brabjerit, sery\n",
      "Do mist:\n",
      "But eves me\n",
      "mis wom he brot afed\n",
      "Phitlt somengy sithtpee.\n",
      "\n",
      "ROPATLATY:\n",
      "I dlave be bedtanght of thus sereel see h\n",
      "\n",
      "train step 100000, loss: 51\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "while trainer.step < max_train_step:\n",
    "    loss = trainer.train(params)\n",
    "    if trainer.step % (max_train_step//10) == 0:\n",
    "        sample_text = sample(params, 0, 200)\n",
    "        print(sample_text)\n",
    "        print()\n",
    "        print('train step {:d}, loss: {:.2g}'.format(trainer.step, loss))\n",
    "        print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with Keras\n",
    "\n",
    "We will write a similar RNN, with the application of [predicting word completions](http://curiousily.com/data-science/2017/05/23/tensorflow-for-hackers-part-5.html) for [Jonathan Swift](https://en.wikipedia.org/wiki/Jonathan_Swift), the author of Gulliver's Travels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras 2.2.4\n",
      "GPU: []\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "import keras\n",
    "print('Keras', keras.__version__)\n",
    "from keras import backend as K\n",
    "print('GPU:', K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is at `../data/Gulliver.txt` and contains the Project Gutenberg's version of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chars: 59\n"
     ]
    }
   ],
   "source": [
    "with open('../data/Gulliver.txt') as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(f'unique chars: {len(chars)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use sequences of length 40 and unroll 3 steps at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples: 102845\n"
     ]
    }
   ],
   "source": [
    "seq_len = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    sentences.append(text[i: i + seq_len])\n",
    "    next_chars.append(text[i + seq_len])\n",
    "print(f'num training examples: {len(sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), seq_len, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the model using Keras' succint API - an [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) (a common and efficient type of RNN) with 128 hidden nodes, followed by a multinomial logistic layer (dense=fully-connected).\n",
    "\n",
    "![LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               96256     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 59)                7611      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 103,867\n",
      "Trainable params: 103,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    keras.layers.LSTM(128, input_shape=(seq_len, len(chars))),\n",
    "    keras.layers.Dense(len(chars)),\n",
    "    keras.layers.Activation('softmax')\n",
    "]\n",
    "model = keras.models.Sequential(layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train with the Adam optimizer, the cross entropy loss function, and use accuracy as a performance metric. \n",
    "To measure accuracy on a test set, we tell Keras to split 5% of the data for a testset.\n",
    "\n",
    "Other training parameters are the batch size - number of samples or sequences per gradient update - and epochs - number of times we want to iterate over the entire data.\n",
    "\n",
    "A nice feature is that we can get the training history object which contains logging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 97702 samples, validate on 5143 samples\n",
      "Epoch 1/20\n",
      "97702/97702 [==============================] - 43s 444us/step - loss: 2.7247 - acc: 0.2461 - val_loss: 2.6824 - val_acc: 0.2543\n",
      "Epoch 2/20\n",
      "97702/97702 [==============================] - 41s 421us/step - loss: 2.3349 - acc: 0.3276 - val_loss: 2.5307 - val_acc: 0.2917\n",
      "Epoch 3/20\n",
      "97702/97702 [==============================] - 39s 397us/step - loss: 2.1851 - acc: 0.3646 - val_loss: 2.4589 - val_acc: 0.3169\n",
      "Epoch 4/20\n",
      "97702/97702 [==============================] - 41s 424us/step - loss: 2.0862 - acc: 0.3902 - val_loss: 2.4049 - val_acc: 0.3284\n",
      "Epoch 5/20\n",
      "97702/97702 [==============================] - 42s 435us/step - loss: 2.0122 - acc: 0.4099 - val_loss: 2.3510 - val_acc: 0.3488\n",
      "Epoch 6/20\n",
      "97702/97702 [==============================] - 40s 414us/step - loss: 1.9506 - acc: 0.4247 - val_loss: 2.3067 - val_acc: 0.3683\n",
      "Epoch 7/20\n",
      "97702/97702 [==============================] - 40s 408us/step - loss: 1.8997 - acc: 0.4378 - val_loss: 2.2662 - val_acc: 0.3718\n",
      "Epoch 8/20\n",
      "97702/97702 [==============================] - 44s 454us/step - loss: 1.8568 - acc: 0.4485 - val_loss: 2.2465 - val_acc: 0.3776\n",
      "Epoch 9/20\n",
      "97702/97702 [==============================] - 43s 439us/step - loss: 1.8184 - acc: 0.4585 - val_loss: 2.2189 - val_acc: 0.3879\n",
      "Epoch 10/20\n",
      "97702/97702 [==============================] - 43s 438us/step - loss: 1.7857 - acc: 0.4677 - val_loss: 2.2217 - val_acc: 0.3885\n",
      "Epoch 11/20\n",
      "97702/97702 [==============================] - 43s 445us/step - loss: 1.7528 - acc: 0.4767 - val_loss: 2.1861 - val_acc: 0.3969\n",
      "Epoch 12/20\n",
      "97702/97702 [==============================] - 43s 437us/step - loss: 1.7240 - acc: 0.4841 - val_loss: 2.1769 - val_acc: 0.3992\n",
      "Epoch 13/20\n",
      "97702/97702 [==============================] - 40s 412us/step - loss: 1.6968 - acc: 0.4926 - val_loss: 2.1759 - val_acc: 0.3935\n",
      "Epoch 14/20\n",
      "97702/97702 [==============================] - 43s 438us/step - loss: 1.6721 - acc: 0.5008 - val_loss: 2.1674 - val_acc: 0.4021\n",
      "Epoch 15/20\n",
      "97702/97702 [==============================] - 39s 402us/step - loss: 1.6483 - acc: 0.5065 - val_loss: 2.1527 - val_acc: 0.4068\n",
      "Epoch 16/20\n",
      "97702/97702 [==============================] - 39s 399us/step - loss: 1.6263 - acc: 0.5128 - val_loss: 2.1465 - val_acc: 0.4066\n",
      "Epoch 17/20\n",
      "97702/97702 [==============================] - 40s 410us/step - loss: 1.6054 - acc: 0.5199 - val_loss: 2.1444 - val_acc: 0.4101\n",
      "Epoch 18/20\n",
      "97702/97702 [==============================] - 54s 548us/step - loss: 1.5863 - acc: 0.5240 - val_loss: 2.1213 - val_acc: 0.4200\n",
      "Epoch 19/20\n",
      "97702/97702 [==============================] - 48s 488us/step - loss: 1.5677 - acc: 0.5292 - val_loss: 2.1285 - val_acc: 0.4132\n",
      "Epoch 20/20\n",
      "97702/97702 [==============================] - 46s 469us/step - loss: 1.5515 - acc: 0.5344 - val_loss: 2.1323 - val_acc: 0.4215\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X, y, \n",
    "    validation_split=0.05, \n",
    "    batch_size=128, \n",
    "    epochs=20, \n",
    "    shuffle=True).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models can be saved to HDF5 files, history can be pickled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../data/keras_rnn_model.h5')\n",
    "with open(\"history.p\", \"wb\") as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../data/keras_rnn_model.h5')\n",
    "with open(\"history.p\", \"rb\") as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the change in accuracy and loss over the training time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a776048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(history['acc'], label='train')\n",
    "ax.plot(history['val_acc'], label='test')\n",
    "ax.set(\n",
    "    title='model accuracy',\n",
    "    ylabel='accuracy',\n",
    "    xlabel='epoch'\n",
    ")\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(history['loss'], label='train')\n",
    "ax.plot(history['val_loss'], label='test')\n",
    "ax.set(\n",
    "    title='model loss',\n",
    "    ylabel='loss',\n",
    "    xlabel='epoch'\n",
    ")\n",
    "ax.legend()\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the model for text completion.\n",
    "\n",
    "First, a one-hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, seq_len, len(chars)))\n",
    "    for t, char in enumerate(text[:seq_len]):\n",
    "        x[0, t, char_indices[char]] = 1.        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function samples from $\\widehat y$, the character probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two function gets input text and predicts at least two more characters until space is encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        \n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the next one makes several predictions, that is, samples the completion distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [\n",
    "        indices_char[idx] + predict_completion(\n",
    "                                text[1:] + indices_char[idx]) \n",
    "        for idx in next_indices\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with some actual quotes from the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    'I likewise delivered up my watch, which the emperor was very curious to see',\n",
    "    'I lay all this while, as the reader may believe, in great uneasiness.',\n",
    "    'But I should have mentioned, that before the principal person began his oration',\n",
    "    'After they were read, I was demanded to swear to the performance of them',\n",
    "    'extending its edges round as wide as his majesty\\'s bed-chamber'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i likewise delivered up my watch, which \n",
      "['i ', 'was ', 'the ', 'had ', 'all ']\n",
      "\n",
      "i lay all this while, as the reader may \n",
      "['of ', 'the ', 'he ', 'a ', 'which ']\n",
      "\n",
      "but i should have mentioned, that before\n",
      "[' of ', ', ', '\\nhis ', '. ', 's ']\n",
      "\n",
      "after they were read, i was demanded to \n",
      "['the ', 'my ', 'be ', 'his ', 'see ']\n",
      "\n",
      "extending its edges round as wide as his\n",
      "[' majesty ', '\\nmajesty ', 'her ', 'e ', ', ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in quotes:\n",
    "    seq = q[:seq_len].lower()\n",
    "    print(seq)\n",
    "    print(predict_completions(seq, 5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Try to run it on some of your text.\n",
    "For example, you can save your terminal history to a file and let the network train on that (`history > history.txt` then remove the line numbers using text editor or even Python).\n",
    "Another option is to feed it with your source code: choose some project, read all source files (you can use [`os.walk`](https://docs.python.org/3.5/library/os.html#os.walk)), and feed it to the network.\n",
    "\n",
    "Have fun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- TensorFlow [RNN tutorial](https://www.tensorflow.org/tutorials/recurrent)\n",
    "- Andrej Karpathy's [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) blogpost\n",
    "- [Obama-RNN](https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0) by samim.\n",
    "- [Gradient checking and advanced optimization](http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization) on Stanford's \"Unsupervised Feature Learning and Deep Learning\" tutorial\n",
    "- [Making a Predictive Keyboard using Recurrent Neural Networks](http://curiousily.com/data-science/2017/05/23/tensorflow-for-hackers-part-5.html) by Venelin Valkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colophon\n",
    "This notebook was written by [Yoav Ram](http://python.yoavram.com) and is part of the [_Deep Learning for Software Developers_](https://python.yoavram.com/Deep4Devs) course.\n",
    "\n",
    "The notebook was written using [Python](http://python.org/) 3.6.3, [IPython](http://ipython.org/) 6.2.1, [Jupyter](http://jupyter.org) 5.1.0.\n",
    "\n",
    "This work is licensed under a CC BY-NC-SA 4.0 International License.\n",
    "\n",
    "![Python logo](https://www.python.org/static/community_logos/python-logo.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataSciPy]",
   "language": "python",
   "name": "conda-env-DataSciPy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
